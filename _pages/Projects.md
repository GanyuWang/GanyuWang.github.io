---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---


### Optimization Efficiency and Privacy in Vertical Federated Learning
*Apr. 2022 - Jan. 2024* 
Developed an innovative Vertical Federated Learning framework that combines various optimization techniques to improve convergence rates while preserving data privacy. Proposed a theoretical analysis of the framework's convergence and differential privacy guarantees, achieving substantial reductions in communication costs. This series of works are published in [NeurIPS 2024](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2b5af479527167d4af78847a9b9b645f-Abstract-Conference.html) and [Machine Learning Journal (MLJ)](https://link.springer.com/article/10.1007/s10994-024-06541-y).


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='projects/a_unified_framework.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


### Kernelized AUC Maximization in Vertical Federated Learning
*Jun. 2023 - Jul. 2024*  
Contributed to the Asynchronous Vertical Federated Kernelized AUC Maximization (AVFKAM) project, designed to enhance model performance on imbalanced datasets. This project demonstrates notable improvements in training efficiency for federated systems. Published in KDD 2024.

### Online Learning in Vertical Federated Learning
*In Progress*  
Researching online learning algorithms tailored for Vertical Federated Learning systems, addressing the unique challenges of dynamic data environments. This work has been submitted to ICLR 2025.

### Black-box Prompt Learning for Cloud-based LLMs in Federated Learning
*In Progress*  
Leading a project to explore prompt learning techniques for cloud-hosted Large Language Models (LLMs), optimizing prompts in a black-box setting using the OpenAI API. This project addresses prompt effectiveness without access to model internals, bringing efficiency and adaptability to federated learning contexts. Submitted to ICLR 2025.
