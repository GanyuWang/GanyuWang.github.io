---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---
<link rel="stylesheet" href="{{ '/assets/css/main.scss' | relative_url }}">

### Optimization Efficiency and Privacy in Vertical Federated Learning
*Apr. 2022 - Jan. 2024*   
Developed an innovative Vertical Federated Learning framework that combines various optimization techniques to improve convergence rates while preserving data privacy. Proposed a theoretical analysis of the framework's convergence and differential privacy guarantees, achieving substantial reductions in communication costs. This series of works are published in [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2b5af479527167d4af78847a9b9b645f-Abstract-Conference.html) and [Machine Learning Journal (MLJ)](https://link.springer.com/article/10.1007/s10994-024-06541-y).



<div style="position: relative; display: inline-block; width: auto;">
  <!-- Badge -->
  <div class="badge">
    NeurIPS 2023
  </div>
  <!-- Image -->
  <img src="/images/a_unified_framework.jpg" alt="A Unified Framework" style="width: 100%; border-radius: 5px;">
</div>


### Kernelized AUC Maximization in Vertical Federated Learning
*Jun. 2023 - Jul. 2024*  
Contributed to the Asynchronous Vertical Federated Kernelized AUC Maximization (AVFKAM) project, designed to enhance model performance on imbalanced datasets. This project demonstrates notable improvements in training efficiency for federated systems. Published in [KDD 2024](https://dl.acm.org/doi/10.1145/3637528.3671930).


<div style="position: relative; display: inline-block; width: auto;">
  <!-- Badge -->
  <div class="badge">
    KDD 2024
  </div>
  <!-- Image -->
  <img src="/images/asy_auc_combine.jpg" alt="Kernelized AUC Maximization" style="width: 100%; border-radius: 5px;">
</div>


### Online Learning in Vertical Federated Learning
*In Progress*  
Leading research on online learning algorithms specifically designed for Vertical Federated Learning systems, addressing the unique challenges posed by vertical federate learning. This work has been submitted to ICLR 2025.

### Black-box Prompt Learning for Cloud-based LLMs in Federated Learning
*In Progress*  
Leading a project to explore prompt learning techniques for cloud-hosted Large Language Models (LLMs), optimizing prompts in a black-box setting using the OpenAI API. This project addresses prompt effectiveness without access to model internals, bringing efficiency and adaptability to federated learning contexts. Submitted to ICLR 2025.
